{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Documentation RAG-QA\n",
    "\n",
    "## Notebook Purpose\n",
    "Data Anaysis for Chunking and Indexing\n",
    " \n",
    "## Tasks\n",
    "- Data Chunk\n",
    "- Indexing\n",
    "\n",
    "## Notable TODOs:\n",
    "- Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/leobit/Development/Projects/aws-doc-ragqa/research\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "if Path.cwd().name == \"notebooks\":\n",
    "\t%cd ..\n",
    "\n",
    "## Extensions\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "\t%load_ext autoreload\n",
    "else:\n",
    "\t%reload_ext autoreload\n",
    "\n",
    "if 'dotenv' not in ipython.extension_manager.loaded:\n",
    "\t%load_ext dotenv\n",
    "else:\n",
    "\t%reload_ext dotenv\n",
    "\n",
    "# if 'cudf.pandas' not in get_ipython().extension_manager.loaded:\n",
    "# \t%load_ext cudf.pandas\n",
    "\n",
    "%autoreload 2\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Config / Utils\n",
    "import config as cfg\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from utils import save_obj, load_obj, run_api\n",
    "\n",
    "@register_cell_magic\n",
    "def pybash(line, cell):\n",
    "\t'''Runs a magic bash with Python Variables'''\n",
    "\tipython.run_cell_magic('bash', '--no-raise-error', cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## GLOBAL INFO\n",
      "Conda Python Version: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.9.final.0\n",
      "Conda Base Path: /opt/miniconda3\n",
      "Conda Base Version: 25.1.1\n",
      "\n",
      "## ENVIRONMENT INFO\n",
      "Active Environment: aws-doc-ragqa\n",
      "Environment Python Version: Python 3.11.13\n",
      "Environment Python Path: /opt/miniconda3/envs/aws-doc-ragqa/bin/python\n",
      "Environment IPython Version: 9.1.0\n",
      "Environment IPykernel Version: 6.29.5\n",
      "\n",
      "## GPU INFO:\n",
      "CUDA Device Initialized "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leobit/Development/Projects/aws-doc-ragqa/research/scripts/notebook_info.sh: line 21: numba: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "GPU Info: Failed to initialize NVML: N/A\n",
      "Failed to properly shut down NVML: N/A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%pybash\n",
    "bash {cfg.path.scripts}/notebook_info.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Chunk\n",
    "\n",
    "- Strategy: Semantic and Hierarchical Chunking  \n",
    "- Parser: MarkdownNodeParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing some chunking documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import MarkdownNodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_files_df = load_obj(cfg.path.data.interim / \"category_files_df_v1.pickle\", as_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['properties', 'resource', 'how-to-guide', 'tutorial', 'concepts',\n",
       "       'security', 'geospatial'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_files_df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/raw/aws_doc_batch_1/aws-properties-events-rule-sagemakerpipelineparameter.md')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_files_df.iloc[0][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = category_files_df.copy()\n",
    "\n",
    "def get_category(df: pd.DataFrame, path: Path):\n",
    "\tcategory = df[df.path == path][\"category\"].values[0]\n",
    "\treturn category\n",
    "\n",
    "def get_metadata(file_path):\n",
    "\tfile_path = Path(file_path)\n",
    "\treturn {\"file_name\": file_path.name, \"category\": get_category(df, file_path)}\n",
    "\n",
    "def check_parser(df: pd.DataFrame, cat: str, qtd_docs: int = 1):\n",
    "\tpaths = df[df.category==cat].sample(qtd_docs)[\"path\"].tolist()\n",
    "\tdocs = SimpleDirectoryReader(\n",
    "\t\tinput_files=paths,\n",
    "\t\tfile_metadata=get_metadata\n",
    "\t).load_data()\n",
    "\tparser = MarkdownNodeParser()\n",
    "\tnodes = parser.get_nodes_from_documents(docs)\n",
    "\tdisplay(Markdown(paths[0]))\n",
    "\treturn nodes, docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Create Custom Project Templates<a name=\"sagemaker-projects-templates-custom\"></a>\n",
       "\n",
       "If the SageMaker\\-provided templates do not meet your needs \\(for example, you want to have more complex orchestration in the CodePipeline with multiple stages or custom approval steps\\), create your own templates\\.\n",
       "\n",
       "We recommend starting by using SageMaker\\-provided templates to understand how to organize your code and resources and build on top of it\\. To do this, after you enable administrator access to the SageMaker templates, log in to the [https://console\\.aws\\.amazon\\.com/servicecatalog/](https://console.aws.amazon.com/servicecatalog/), choose **Portfolios**, then choose **Imported**\\. For information about Service Catalog, see [Overview of Service Catalog](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/what-is_concepts.html) in the *Service Catalog User Guide*\\.\n",
       "\n",
       "Create your own project templates to customize your MLOps project\\. SageMaker project templates are Service Catalog–provisioned products to provision the resources for your MLOps project\\. \n",
       "\n",
       "To create a custom project template, complete the following steps\\.\n",
       "\n",
       "1. Create a portfolio\\. For information, see [Step 3: Create an Service Catalog Portfolio](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-portfolio.html)\\.\n",
       "\n",
       "1. Create a product\\. A product is a CloudFormation template\\. You can create multiple versions of the product\\. For information, see [Step 4: Create an Service Catalog Product](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-product.html)\\.\n",
       "\n",
       "   For the product to work with SageMaker projects, add the following parameters to your product template\\.\n",
       "\n",
       "   ```\n",
       "   SageMakerProjectName:\n",
       "   Type: String\n",
       "   Description: Name of the project\n",
       "   \n",
       "   SageMakerProjectId:\n",
       "   Type: String\n",
       "   Description: Service generated Id of the project.\n",
       "   ```\n",
       "**Important**  \n",
       "We recommend that you wrap the CodeCommit repository into the SageMaker code repository for the project's repositories to be visible in VPC mode\\. The sample template and required addition are shown in the following code samples\\.  \n",
       "Original \\(sample\\) template:  \n",
       "\n",
       "   ```\n",
       "   ModelBuildCodeCommitRepository:\n",
       "       Type: AWS::CodeCommit::Repository\n",
       "       Properties:\n",
       "         # Max allowed length: 100 chars\n",
       "         RepositoryName: !Sub sagemaker-${SageMakerProjectName}-${SageMakerProjectId}-modelbuild # max: 10+33+15+10=68\n",
       "         RepositoryDescription: !Sub SageMaker Model building workflow infrastructure as code for the Project ${SageMakerProjectName}\n",
       "         Code:\n",
       "           S3:\n",
       "             Bucket: SEEDCODE_BUCKETNAME\n",
       "             Key: toolchain/model-building-workflow-v1.0.zip\n",
       "           BranchName: main\n",
       "   ```\n",
       "Additional content to add in VPC mode:  \n",
       "\n",
       "   ```\n",
       "   SageMakerRepository:\n",
       "       Type: AWS::SageMaker::CodeRepository\n",
       "       Properties:\n",
       "           GitConfig:\n",
       "               RepositoryUrl: !GetAtt ModelBuildCodeCommitRepository.CloneUrlHttp\n",
       "               Branch: main\n",
       "   ```\n",
       "\n",
       "1. Add a launch constraint\\. A launch constraint designates an IAM role that Service Catalog assumes when a user launches a product\\. For information, see [Step 6: Add a Launch Constraint to Assign an IAM Role](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-launchconstraint.html)\\.\n",
       "\n",
       "1. Provision the product on [https://console\\.aws\\.amazon\\.com/servicecatalog/](https://console.aws.amazon.com/servicecatalog/) to test the template\\. If you are satisfied with your template, continue to the next step to make the template available in Studio\\.\n",
       "\n",
       "1. Grant access to the Service Catalog portfolio that you created in step 1 to your Studio execution role\\. Use either the Studio domain execution role or a user role that has Studio access\\. For information about adding a role to the portfolio, see [Step 7: Grant End Users Access to the Portfolio](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-deploy.html)\\.\n",
       "\n",
       "1. To make your project template available in your **Organization templates** list in Studio, create a tag with the following key and value to the Service Catalog product you created in step 2\\.\n",
       "   + **key**: `sagemaker:studio-visibility`\n",
       "   + **value**: `true`\n",
       "\n",
       "After you complete these steps, Studio users in your organization can create a project with the template you created by following the steps in [Create an MLOps Project using Amazon SageMaker Studio](sagemaker-projects-create.md) and choosing **Organization templates** when you choose a template\\."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = category_files_df\n",
    "cat = \"tutorial\"\n",
    "qtd_docs = 1\n",
    "nodes, docs = check_parser(category_files_df, cat, qtd_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'sagemaker-projects-templates-custom.md', 'category': 'tutorial'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed into 1 nodes (chunks).\n",
      "--- Node 1 ---\n",
      "Metadata: {'file_name': 'sagemaker-projects-templates-custom.md', 'category': 'tutorial', 'header_path': '/'}\n",
      "Content: # Create Custom Project Templates<a name=\"sagemaker-projects-templates-custom\"></a>\n",
      "\n",
      "If the SageMaker\\-provided templates do not meet your needs \\(for example, you want to have more complex orchestration in the CodePipeline with multiple stages or custom approval steps\\), create your own templates\\.\n",
      "\n",
      "We recommend starting by using SageMaker\\-provided templates to understand how to organize your code and resources and build on top of it\\. To do this, after you enable administrator access to the SageMaker templates, log in to the [https://console\\.aws\\.amazon\\.com/servicecatalog/](https://console.aws.amazon.com/servicecatalog/), choose **Portfolios**, then choose **Imported**\\. For information about Service Catalog, see [Overview of Service Catalog](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/what-is_concepts.html) in the *Service Catalog User Guide*\\.\n",
      "\n",
      "Create your own project templates to customize your MLOps project\\. SageMaker project templates are Service Catalog–provisioned products to provision the resources for your MLOps project\\. \n",
      "\n",
      "To create a custom project template, complete the following steps\\.\n",
      "\n",
      "1. Create a portfolio\\. For information, see [Step 3: Create an Service Catalog Portfolio](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-portfolio.html)\\.\n",
      "\n",
      "1. Create a product\\. A product is a CloudFormation template\\. You can create multiple versions of the product\\. For information, see [Step 4: Create an Service Catalog Product](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-product.html)\\.\n",
      "\n",
      "   For the product to work with SageMaker projects, add the following parameters to your product template\\.\n",
      "\n",
      "   ```\n",
      "   SageMakerProjectName:\n",
      "   Type: String\n",
      "   Description: Name of the project\n",
      "   \n",
      "   SageMakerProjectId:\n",
      "   Type: String\n",
      "   Description: Service generated Id of the project.\n",
      "   ```\n",
      "**Important**  \n",
      "We recommend that you wrap the CodeCommit repository into the SageMaker code repository for the project's repositories to be visible in VPC mode\\. The sample template and required addition are shown in the following code samples\\.  \n",
      "Original \\(sample\\) template:  \n",
      "\n",
      "   ```\n",
      "   ModelBuildCodeCommitRepository:\n",
      "       Type: AWS::CodeCommit::Repository\n",
      "       Properties:\n",
      "         # Max allowed length: 100 chars\n",
      "         RepositoryName: !Sub sagemaker-${SageMakerProjectName}-${SageMakerProjectId}-modelbuild # max: 10+33+15+10=68\n",
      "         RepositoryDescription: !Sub SageMaker Model building workflow infrastructure as code for the Project ${SageMakerProjectName}\n",
      "         Code:\n",
      "           S3:\n",
      "             Bucket: SEEDCODE_BUCKETNAME\n",
      "             Key: toolchain/model-building-workflow-v1.0.zip\n",
      "           BranchName: main\n",
      "   ```\n",
      "Additional content to add in VPC mode:  \n",
      "\n",
      "   ```\n",
      "   SageMakerRepository:\n",
      "       Type: AWS::SageMaker::CodeRepository\n",
      "       Properties:\n",
      "           GitConfig:\n",
      "               RepositoryUrl: !GetAtt ModelBuildCodeCommitRepository.CloneUrlHttp\n",
      "               Branch: main\n",
      "   ```\n",
      "\n",
      "1. Add a launch constraint\\. A launch constraint designates an IAM role that Service Catalog assumes when a user launches a product\\. For information, see [Step 6: Add a Launch Constraint to Assign an IAM Role](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-launchconstraint.html)\\.\n",
      "\n",
      "1. Provision the product on [https://console\\.aws\\.amazon\\.com/servicecatalog/](https://console.aws.amazon.com/servicecatalog/) to test the template\\. If you are satisfied with your template, continue to the next step to make the template available in Studio\\.\n",
      "\n",
      "1. Grant access to the Service Catalog portfolio that you created in step 1 to your Studio execution role\\. Use either the Studio domain execution role or a user role that has Studio access\\. For information about adding a role to the portfolio, see [Step 7: Grant End Users Access to the Portfolio](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/getstarted-deploy.html)\\.\n",
      "\n",
      "1. To make your project template available in your **Organization templates** list in Studio, create a tag with the following key and value to the Service Catalog product you created in step 2\\.\n",
      "   + **key**: `sagemaker:studio-visibility`\n",
      "   + **value**: `true`\n",
      "\n",
      "After you complete these steps, Studio users in your organization can create a project with the template you created by following the steps in [Create an MLOps Project using Amazon SageMaker Studio](sagemaker-projects-create.md) and choosing **Organization templates** when you choose a template\\....\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parsed into {len(nodes)} nodes (chunks).\")\n",
    "for i, node in enumerate(nodes[:10]):\n",
    "\tprint(f\"--- Node {i+1} ---\")\n",
    "\tprint(f\"Metadata: {node.metadata}\")\n",
    "\tprint(f\"Content: {node.get_content()[:5000]}...\")\n",
    "\tprint(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "import config as cfg\n",
    "import weave\n",
    "from pathlib import Path\n",
    "from typing import NoReturn\n",
    "\n",
    "# llama-index imports\n",
    "from llama_index.core import (\n",
    "\tVectorStoreIndex,\n",
    "\tSimpleDirectoryReader,\n",
    "\tStorageContext,\n",
    "\tSettings,\n",
    ")\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "# Other libraries\n",
    "import qdrant_client\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9ec1410b7a131fa602a7e743856245c1a9a1162f857d8e02027cd59f5ec9c1d5\n"
     ]
    }
   ],
   "source": [
    "%%pybash\n",
    "docker run -d -p 6333:6333 -p 6334:6334 qdrant/qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "category_files_df = load_obj(cfg.path.data.interim / \"category_files_df_v1.pickle\", as_df=True)\n",
    "\n",
    "weave.init(\"aws_doc_ragqa_demo\")\n",
    "\n",
    "logger = logging.getLogger(\"llamaindex\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def get_category(df: pd.DataFrame, path: Union[Path, str]) -> str:\n",
    "\t\"\"\"\n",
    "\tRetrieve the category for a given file path from the dataframe.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdf (pd.DataFrame): DataFrame containing 'path' and 'category' columns.\n",
    "\t\tpath (Union[Path, str]): The file path to look up.\n",
    "\n",
    "\tReturns:\n",
    "\t\tstr: The category associated with the file path.\n",
    "\n",
    "\tRaises:\n",
    "\t\tIndexError: If the path is not found in the DataFrame.\n",
    "\t\"\"\"\n",
    "\tcategory = df[df.path == Path(path)][\"category\"].values[0]\n",
    "\tlogger.debug(f\"Category for {path}: {category}\")\n",
    "\treturn category\n",
    "\n",
    "def get_metadata(file_path: Union[Path, str]) -> Dict[str, str]:\n",
    "\t\"\"\"\n",
    "\tGenerate metadata dictionary for a given file path.\n",
    "\n",
    "\tArgs:\n",
    "\t\tfile_path (Union[Path, str]): The file path.\n",
    "\n",
    "\tReturns:\n",
    "\t\tDict[str, str]: Metadata including file name and category.\n",
    "\t\"\"\"\n",
    "\tfile_path = Path(file_path)\n",
    "\tmeta = {\"file_name\": file_path.name, \"category\": get_category(category_files_df, file_path)}\n",
    "\tlogger.debug(f\"Metadata for {file_path}: {meta}\")\n",
    "\treturn meta\n",
    "\n",
    "def get_nodes(df: pd.DataFrame) -> List[Any]:\n",
    "\t\"\"\"\n",
    "\tParse markdown documents into nodes using the provided DataFrame.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdf (pd.DataFrame): DataFrame with a 'path' column.\n",
    "\n",
    "\tReturns:\n",
    "\t\tList[Any]: List of parsed nodes.\n",
    "\t\"\"\"\n",
    "\tlogger.info(\"Loading documents and parsing nodes...\")\n",
    "\tpaths = df.path.tolist()\n",
    "\tdocs = SimpleDirectoryReader(\n",
    "\t\tinput_files=paths,\n",
    "\t\tfile_metadata=get_metadata\n",
    "\t).load_data()\n",
    "\tparser = MarkdownNodeParser()\n",
    "\tnodes = parser.get_nodes_from_documents(docs)\n",
    "\tlogger.info(f\"Parsed {len(nodes)} nodes from {len(paths)} documents.\")\n",
    "\treturn nodes\n",
    "\n",
    "def set_llm_aws() -> None:\n",
    "\t\"\"\"\n",
    "\tInitialize Bedrock LLM and Embedding model for AWS and set them in Settings.\n",
    "\t\"\"\"\n",
    "\tllm_model_id = cfg.app.aws.llm_model_id\n",
    "\tembed_model_id = cfg.app.aws.embedding_model_id\n",
    "\tregion_name = cfg.app.aws.region\n",
    "\taws_session_token = os.environ[\"AWS_BEARER_TOKEN_BEDROCK\"]\n",
    "\t\n",
    "\tlogger.info(f\"Setting AWS LLM: {llm_model_id}, Embedding: {embed_model_id}\")\n",
    "\tllm = Bedrock(\n",
    "\t\tmodel=llm_model_id,\n",
    "\t\tregion_name=region_name,\n",
    "\t\taws_session_token=aws_session_token\n",
    "\t)\n",
    "\tembed_model = BedrockEmbedding(\n",
    "\t\tmodel_name=embed_model_id,\n",
    "\t\tregion_name=region_name,\n",
    "\t\taws_session_token=aws_session_token\n",
    "\t)\n",
    "\tSettings.llm = llm\n",
    "\tSettings.embed_model = embed_model\n",
    "\n",
    "def set_llm_gemini() -> None:\n",
    "\t\"\"\"\n",
    "\tInitialize Gemini LLM and Embedding model and set them in Settings.\n",
    "\t\"\"\"\n",
    "\tllm_model_id = cfg.app.gemini.llm_model_id\n",
    "\tembed_model_id = cfg.app.gemini.embedding_model_id\n",
    "\t\n",
    "\tlogger.info(f\"Setting Gemini LLM: {llm_model_id}, Embedding: {embed_model_id}\")\n",
    "\tllm = Gemini(model=llm_model_id)\n",
    "\tembed_model = GeminiEmbedding(model_name=embed_model_id)\n",
    "\tSettings.llm = llm\n",
    "\tSettings.embed_model = embed_model\n",
    "\n",
    "def get_model_provider():\n",
    "\tllm_model = Settings.llm.model\n",
    "\tembed_model = Settings.embed_model.model_name\n",
    "\t\n",
    "\tif (llm_model == cfg.app.aws.llm_model_id) and (embed_model == cfg.app.aws.embedding_model_id):\n",
    "\t\treturn \"aws\"\n",
    "\telif (llm_model == cfg.app.gemini.llm_model_id) and (embed_model == cfg.app.gemini.embedding_model_id):\n",
    "\t\treturn \"gemini\"\n",
    "\telse:\n",
    "\t\treturn None\n",
    "\t\n",
    "def set_model_provider(model_provider: str) -> None:\n",
    "\tcur_model_provider = get_model_provider()\n",
    "\tif model_provider != cur_model_provider:\n",
    "\t\tlogger.info(f\"The current model is: {cur_model_provider}\")\n",
    "\t\tif model_provider == \"aws\":\n",
    "\t\t\tlogger.info(\"Setting AWS Model...\")\n",
    "\t\t\tset_llm_aws()\n",
    "\t\telif model_provider == \"gemini\":\n",
    "\t\t\tlogger.info(\"Setting Gemini Model...\")\n",
    "\t\t\tset_llm_gemini()\n",
    "\t\telse:\n",
    "\t\t\tlogger.warning(f\"Unknown model provider: {model_provider}. Defaulting to AWS.\")\n",
    "\t\t\tset_llm_aws()\n",
    "\telse:\n",
    "\t\tlogger.info(\"The Model provider is already set.\")\n",
    "\n",
    "def qdrant_vector_store(model_provider: str = \"aws\") -> QdrantVectorStore:\n",
    "\t\"\"\"\n",
    "\tCreate a QdrantVectorStore instance using configuration.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tmodel_provider (str, optional): Model provider, \"aws\" or \"gemini\". Defaults to \"aws\".\n",
    "\tReturns:\n",
    "\t\tQdrantVectorStore: The vector store instance.\n",
    "\t\"\"\"\n",
    "\tcollection_name = getattr(cfg.app.qdrant.collection, model_provider)\n",
    "\turl = cfg.app.qdrant.url\n",
    "\t\n",
    "\tlogger.info(f\"Connecting to Qdrant at {url}, collection: {collection_name}\")\n",
    "\tclient = qdrant_client.QdrantClient(url=url)\n",
    "\tvector_store = QdrantVectorStore(\n",
    "\t\tclient=client, \n",
    "\t\tcollection_name=collection_name\n",
    "\t)\n",
    "\treturn vector_store\n",
    "\n",
    "def check_collection_exists(model_provider: str = \"aws\") -> bool:\n",
    "\t\"\"\"\n",
    "\tCheck if the Qdrant collection exists.\n",
    "\tArgs:\n",
    "\t\tmodel_provider (str, optional): Model provider, \"aws\" or \"gemini\". Defaults to \"aws\".\n",
    "\n",
    "\tReturns:\n",
    "\t\tbool: True if the collection exists, False otherwise.\n",
    "\t\"\"\"\n",
    "\tcollection_name = getattr(cfg.app.qdrant.collection, model_provider)\n",
    "\turl = cfg.app.qdrant.url\n",
    "\tclient = qdrant_client.QdrantClient(url=url)\n",
    "\tcollection_exists = client.collection_exists(collection_name=collection_name)\n",
    "\tif collection_exists:\n",
    "\t\tlogger.info(f\"Collection '{collection_name}' exists!\")\n",
    "\telse:\n",
    "\t\tlogger.info(f\"Collection '{collection_name}' does not exist!\")\n",
    "\treturn collection_exists\n",
    "\n",
    "def build_index(\n",
    "\tvector_store: QdrantVectorStore,\n",
    "\tnodes: List[Any],\n",
    "\tmodel_provider: str = \"aws\",\n",
    "\tforce_reindex: bool = False\n",
    ") -> VectorStoreIndex:\n",
    "\t\"\"\"\n",
    "\tBuild or load a VectorStoreIndex from Qdrant, setting up the LLM and embedding model.\n",
    "\n",
    "\tArgs:\n",
    "\t\tvector_store (QdrantVectorStore): The vector store instance.\n",
    "\t\tnodes (List[Any]): List of nodes to index.\n",
    "\t\tmodel_provider (str, optional): Model provider, \"aws\" or \"gemini\". Defaults to \"aws\".\n",
    "\t\tforce_reindex (bool, optional): If True, force reindexing. Defaults to False.\n",
    "\n",
    "\tReturns:\n",
    "\t\tVectorStoreIndex: The index instance.\n",
    "\t\"\"\"\n",
    "\tlogger.info(f\"Building index with model provider: {model_provider}, force_reindex={force_reindex}\")\n",
    "\tcollections_exists = check_collection_exists(model_provider)\n",
    "\n",
    "\t# Setup LLM llamaindex settings\n",
    "\tset_model_provider()\n",
    "\n",
    "\tif not force_reindex and collections_exists:\n",
    "\t\tlogger.info(\"Index already exists. Loading from Qdrant.\")\n",
    "\t\tindex = VectorStoreIndex.from_vector_store(vector_store)\n",
    "\telse:\n",
    "\t\tlogger.info(\"Building a new index in Qdrant.\")\n",
    "\t\tstorage_context = StorageContext.from_defaults(\n",
    "\t\t\tvector_store=vector_store,\n",
    "\t\t)\n",
    "\t\tindex = VectorStoreIndex(\n",
    "\t\t\tnodes, \n",
    "\t\t\tstorage_context=storage_context,\n",
    "\t\t\tshow_progress=True,\n",
    "\t\t)\n",
    "\treturn index\n",
    "\n",
    "def get_index(\n",
    "\tdf: pd.DataFrame, \n",
    "\tmodel_provider: str = \"aws\", \n",
    "\tforce_reindex: bool = False\n",
    ") -> VectorStoreIndex:\n",
    "\t\"\"\"\n",
    "\tGet or build a VectorStoreIndex for the given DataFrame.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdf (pd.DataFrame): DataFrame with file paths and categories.\n",
    "\t\tmodel_provider (str, optional): Model provider, \"aws\" or \"gemini\". Defaults to \"aws\".\n",
    "\t\tforce_reindex (bool, optional): If True, force reindexing. Defaults to False.\n",
    "\n",
    "\tReturns:\n",
    "\t\tVectorStoreIndex: The index instance.\n",
    "\t\"\"\"\n",
    "\tlogger.info(\"Preparing to get or build index...\")\n",
    "\tnodes = get_nodes(df)\n",
    "\tvector_store = qdrant_vector_store(model_provider)\n",
    "\tindex = build_index(vector_store, nodes, model_provider, force_reindex)\n",
    "\tlogger.info(\"Index ready.\")\n",
    "\treturn index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llamaindex:Preparing to get or build index...\n",
      "INFO:llamaindex:Loading documents and parsing nodes...\n",
      "Generating embeddings:   0%|          | 9/1826 [2:03:24<415:15:30, 822.75s/it]\n",
      "INFO:llamaindex:Parsed 1826 nodes from 336 documents.\n",
      "INFO:llamaindex:Connecting to Qdrant at http://localhost:6333, collection: sagemaker_docs_v1\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sagemaker_docs_v1/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sagemaker_docs_v1 \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Building index with model provider: aws, force_reindex=False\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sagemaker_docs_v1/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Collection 'sagemaker_docs_v1' exists!\n",
      "INFO:llamaindex:Setting AWS LLM: us.anthropic.claude-3-haiku-20240307-v1:0, Embedding: amazon.titan-embed-text-v2:0\n",
      "INFO:botocore.tokens:Found token in environment variables.\n",
      "INFO:botocore.tokens:Found token in environment variables.\n",
      "INFO:llamaindex:Index already exists. Loading from Qdrant.\n",
      "INFO:llamaindex:Index ready.\n"
     ]
    }
   ],
   "source": [
    "# AWS Indexing\n",
    "# Collection = sagemaker_docs_v1\n",
    "df = category_files_df.copy()\n",
    "aws_index = get_index(df)\n",
    "# aws_index = get_index(df, force_reindex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llamaindex:Preparing to get or build index...\n",
      "INFO:llamaindex:Loading documents and parsing nodes...\n",
      "Generating embeddings:  13%|█▎        | 239/1826 [10:46<1:11:35,  2.71s/it]\n",
      "Generating embeddings:   0%|          | 9/1826 [03:58<13:22:01, 26.48s/it]\n",
      "INFO:llamaindex:Parsed 1826 nodes from 336 documents.\n",
      "INFO:llamaindex:Connecting to Qdrant at http://localhost:6333, collection: sagemaker_docs_v1.1\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sagemaker_docs_v1.1/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Building index with model provider: gemini, force_reindex=False\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sagemaker_docs_v1.1/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Collection 'sagemaker_docs_v1.1' does not exist!\n",
      "INFO:llamaindex:Setting Gemini LLM: models/gemini-1.5-flash, Embedding: models/embedding-001\n",
      "INFO:llamaindex:Building a new index in Qdrant.\n",
      "Generating embeddings: 100%|██████████| 1826/1826 [11:02<00:00,  2.76it/s]\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1 \"HTTP/1.1 200 OK\"\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Trace output size (17369345 bytes) exceeds the maximum allowed size of 3670016 bytes. Output may be dropped.\n",
      "WARNING:weave.trace.weave_client:Trace output size (17369345 bytes) exceeds the maximum allowed size of 3670016 bytes. Output may be dropped.\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/index?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sagemaker_docs_v1.1 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sagemaker_docs_v1.1/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Index ready.\n"
     ]
    }
   ],
   "source": [
    "# Gemini Indexing\n",
    "# Collection = sagemaker_docs_v1.1\n",
    "df = category_files_df.copy()\n",
    "gemini_index = get_index(df, model_provider=\"gemini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_index(index: VectorStoreIndex, model_provider: str, query: str) -> None:\n",
    "    \"\"\"\n",
    "    Query the index and print the response and sources.\n",
    "\n",
    "    Args:\n",
    "        index (VectorStoreIndex): The index to query.\n",
    "        query (str): The query string.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    logger.info(f\"Querying index: {query}\")\n",
    "    set_model_provider(model_provider)\n",
    "    query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "    response = query_engine.query(query)\n",
    "    print(f\"\\nQ: {query}\")\n",
    "    print(f\"A: {response.response}\")\n",
    "    print(\"Sources:\")\n",
    "    for node in response.source_nodes:\n",
    "        file_name = node.metadata.get('file_name', 'N/A')\n",
    "        category = node.metadata.get('category', 'N/A')\n",
    "        text = node.text\n",
    "        score = node.score\n",
    "        print(f\"  - File: {file_name} \\nCategory: {category} \\nScore: {score:.4f}\")\n",
    "        print(f\"  - Text: {text}\")\n",
    "        print('-' * 20)\n",
    "        print()\n",
    "    print('-' * 100)\n",
    "    print('-' * 100)\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import load_config\n",
    "cfg = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llamaindex:Querying index: What is the Maximum length of the 'Value' property for a SageMakerPipelineParameter in an Events Rule?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llamaindex:The Model provider is already set.\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sagemaker_docs_v1/points/search \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What is the Maximum length of the 'Value' property for a SageMakerPipelineParameter in an Events Rule?\n",
      "A: The maximum length of the 'Value' property for a SageMakerPipelineParameter in an Events Rule is 1024 characters.\n",
      "Sources:\n",
      "  - File: aws-properties-events-rule-sagemakerpipelineparameter.md \n",
      "Category: properties \n",
      "Score: 0.6366\n",
      "  - Text: ### JSON<a name=\"aws-properties-events-rule-sagemakerpipelineparameter-syntax.json\"></a>\n",
      "\n",
      "```\n",
      "{\n",
      "  \"[Name](#cfn-events-rule-sagemakerpipelineparameter-name)\" : String,\n",
      "  \"[Value](#cfn-events-rule-sagemakerpipelineparameter-value)\" : String\n",
      "}\n",
      "```\n",
      "--------------------\n",
      "\n",
      "  - File: aws-properties-events-rule-sagemakerpipelineparameter.md \n",
      "Category: properties \n",
      "Score: 0.6119\n",
      "  - Text: ### YAML<a name=\"aws-properties-events-rule-sagemakerpipelineparameter-syntax.yaml\"></a>\n",
      "\n",
      "```\n",
      "  [Name](#cfn-events-rule-sagemakerpipelineparameter-name): String\n",
      "  [Value](#cfn-events-rule-sagemakerpipelineparameter-value): String\n",
      "```\n",
      "--------------------\n",
      "\n",
      "  - File: aws-properties-events-rule-sagemakerpipelineparameter.md \n",
      "Category: properties \n",
      "Score: 0.5872\n",
      "  - Text: ## Properties<a name=\"aws-properties-events-rule-sagemakerpipelineparameter-properties\"></a>\n",
      "\n",
      "`Name`  <a name=\"cfn-events-rule-sagemakerpipelineparameter-name\"></a>\n",
      "Name of parameter to start execution of a SageMaker Model Building Pipeline\\.  \n",
      "*Required*: Yes  \n",
      "*Type*: String  \n",
      "*Minimum*: `1`  \n",
      "*Maximum*: `256`  \n",
      "*Pattern*: `^[a-zA-Z0-9](-*[a-zA-Z0-9])*$`  \n",
      "*Update requires*: [No interruption](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-no-interrupt)\n",
      "\n",
      "`Value`  <a name=\"cfn-events-rule-sagemakerpipelineparameter-value\"></a>\n",
      "Value of parameter to start execution of a SageMaker Model Building Pipeline\\.  \n",
      "*Required*: Yes  \n",
      "*Type*: String  \n",
      "*Maximum*: `1024`  \n",
      "*Update requires*: [No interruption](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-update-behaviors.html#update-no-interrupt)\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = \"What is the Maximum length of the 'Value' property for a SageMakerPipelineParameter in an Events Rule?\"\n",
    "a = query_index(index=aws_index, model_provider=\"aws\", query=q)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is SageMaker?',\n",
       " 'What are all AWS regions where SageMaker is available?',\n",
       " 'How to check if an endpoint is KMS encrypted?',\n",
       " 'What are SageMaker Geospatial capabilities?']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = cfg.templates.questions\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llamaindex:Querying index: What is SageMaker?\n",
      "INFO:llamaindex:The Model provider is already set.\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sagemaker_docs_v1/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Querying index: What are all AWS regions where SageMaker is available?\n",
      "INFO:llamaindex:The Model provider is already set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What is SageMaker?\n",
      "A: Amazon SageMaker is a fully managed service that enables developers and data scientists to build, train, and deploy machine learning models. It provides a comprehensive platform for all stages of the machine learning lifecycle, from data preparation to model deployment. SageMaker aims to simplify the process of creating and managing machine learning solutions, making it accessible to a wide range of users regardless of their level of expertise in machine learning.\n",
      "Sources:\n",
      "  - File: examples-sagemaker.md \n",
      "Category: tutorial \n",
      "Score: 0.6962\n",
      "  - Text: # Working with Amazon SageMaker<a name=\"examples-sagemaker\"></a>\n",
      "\n",
      " Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning \\(ML\\) models\\. See the following resources for complete code examples with instructions\\.\n",
      "\n",
      " [Link to Github](https://github.com/awsdocs/aws-doc-sdk-examples/tree/master/javav2/example_code/sagemaker) \n",
      "\n",
      " [Link to AWS Code Sample Catalog](http://docs.aws.amazon.com/code-samples/latest/catalog/code-catalog-javav2-example_code-sagemaker.html)\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-projects-whatis.md \n",
      "Category: concepts \n",
      "Score: 0.6298\n",
      "  - Text: ## When Should You Use a SageMaker Project?<a name=\"sagemaker-projects-when\"></a>\n",
      "\n",
      "While notebooks are helpful for model building and experimentation, a team of data scientists and ML engineers sharing code needs a more scalable way to maintain code consistency and strict version control\\.\n",
      "\n",
      "Every organization has its own set of standards and practices that provide security and governance for its AWS environment\\. SageMaker provides a set of first\\-party templates for organizations that want to quickly get started with ML workflows and CI/CD\\. The templates include projects that use AWS\\-native services for CI/CD, such as AWS CodeBuild, AWS CodePipeline, and AWS CodeCommit\\. The templates also offer the option to create projects that use third\\-party tools, such as Jenkins and GitHub\\. For a list of the project templates that SageMaker provides, see [Use SageMaker\\-Provided Project Templates](sagemaker-projects-templates-sm.md)\\.\n",
      "\n",
      "Organizations often need tight control over the MLOps resources that they provision and manage\\. Such responsibility assumes certain tasks, including configuring IAM roles and policies, enforcing resource tags, enforcing encryption, and decoupling resources across multiple accounts\\. SageMaker Projects can support all these tasks through custom template offerings where organizations use AWS CloudFormation templates to define the resources needed for an ML workflow\\. Data Scientists can choose a template to bootstrap and pre\\-configure their ML workflow\\. These custom templates are created as Service Catalog products and you can provision them in the Studio UI under **Organization Templates**\\. The Service Catalog is a service that helps organizations create and manage catalogs of products that are approved for use on AWS\\. For more information about creating custom templates, see [Build Custom SageMaker Project Templates – Best Practices](http://aws.amazon.com/blogs/machine-learning/build-custom-sagemaker-project-templates-best-practices/)\\.\n",
      "\n",
      "SageMaker Projects can help you manage your Git repositories so that you can collaborate more efficiently across teams, ensure code consistency, and support CI/CD\\. SageMaker Projects can help you with the following tasks:\n",
      "+ Organize all entities of the ML lifecycle under one project\\.\n",
      "+ Establish a single\\-click approach to set up standard ML infrastructure for model training and deployment that incorporates best practices\\.\n",
      "+ Create and share templates for ML infrastructure to serve multiple use cases\\.\n",
      "+ Leverage SageMaker\\-provided pre\\-built templates to quickly start focusing on model building, or create custom templates with organization\\-specific resources and guidelines\\.\n",
      "+ Integrate with tools of your choice by extending the project templates\\. For an example, see [Create a SageMaker Project to integrate with GitLab and GitLab Pipelines](http://aws.amazon.com/blogs/machine-learning/build-mlops-workflows-with-amazon-sagemaker-projects-gitlab-and-gitlab-pipelines/)\\.\n",
      "+ Organize all entities of the ML lifecycle under one project\\.\n",
      "--------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sagemaker_docs_v1/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Querying index: How to check if an endpoint is KMS encrypted?\n",
      "INFO:llamaindex:The Model provider is already set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are all AWS regions where SageMaker is available?\n",
      "A: I apologize, but I don't have information about the specific AWS regions where Amazon SageMaker is available based on the given context. The provided information focuses on general descriptions of SageMaker and its integration with AWS Marketplace, but does not include details about regional availability. For the most up-to-date and accurate information on SageMaker's regional availability, you would need to check the official AWS documentation or contact AWS support directly.\n",
      "Sources:\n",
      "  - File: examples-sagemaker.md \n",
      "Category: tutorial \n",
      "Score: 0.5683\n",
      "  - Text: # Working with Amazon SageMaker<a name=\"examples-sagemaker\"></a>\n",
      "\n",
      " Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning \\(ML\\) models\\. See the following resources for complete code examples with instructions\\.\n",
      "\n",
      " [Link to Github](https://github.com/awsdocs/aws-doc-sdk-examples/tree/master/javav2/example_code/sagemaker) \n",
      "\n",
      " [Link to AWS Code Sample Catalog](http://docs.aws.amazon.com/code-samples/latest/catalog/code-catalog-javav2-example_code-sagemaker.html)\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-marketplace.md \n",
      "Category: concepts \n",
      "Score: 0.5310\n",
      "  - Text: # Buy and Sell Amazon SageMaker Algorithms and Models in AWS Marketplace<a name=\"sagemaker-marketplace\"></a>\n",
      "\n",
      "Amazon SageMaker integrates with AWS Marketplace, enabling developers to charge other SageMaker users for the use of their algorithms and model packages\\. AWS Marketplace is a curated digital catalog that makes it easy for customers to find, buy, deploy, and manage third\\-party software and services that customers need to build solutions and run their businesses\\. AWS Marketplace includes thousands of software listings in popular categories, such as security, networking, storage, machine learning, business intelligence, database, and DevOps\\. It simplifies software licensing and procurement with flexible pricing options and multiple deployment methods\\. \n",
      "\n",
      "For information, see [AWS Marketplace Documentation](https://docs.aws.amazon.com/marketplace/index.html#lang/en_us)\\.\n",
      "--------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sagemaker_docs_v1/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Querying index: What are SageMaker Geospatial capabilities?\n",
      "INFO:llamaindex:The Model provider is already set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: How to check if an endpoint is KMS encrypted?\n",
      "A: To check if an Amazon SageMaker endpoint is encrypted using a KMS key, you can use the SAGEMAKER_ENDPOINT_CONFIGURATION_KMS_KEY_CONFIGURED rule. This rule periodically checks whether a KMS key is configured for SageMaker endpoint configurations.\n",
      "\n",
      "The rule will evaluate as NON_COMPLIANT if the 'KmsKeyId' is not specified for the SageMaker endpoint configuration. This means that if an endpoint configuration is found without a KMS key specified, it will be flagged as non-compliant.\n",
      "\n",
      "You can also optionally specify a list of allowed KMS key ARNs using the 'kmsKeyArns' parameter. This allows you to ensure that only specific KMS keys are being used for encryption.\n",
      "\n",
      "This check is performed periodically across most AWS regions, helping you maintain consistent encryption practices for your SageMaker endpoints.\n",
      "Sources:\n",
      "  - File: sagemaker-endpoint-configuration-kms-key-configured.md \n",
      "Category: security \n",
      "Score: 0.6241\n",
      "  - Text: # sagemaker\\-endpoint\\-configuration\\-kms\\-key\\-configured<a name=\"sagemaker-endpoint-configuration-kms-key-configured\"></a>\n",
      "\n",
      "Checks whether AWS Key Management Service \\(KMS\\) key is configured for an Amazon SageMaker endpoint configuration\\. The rule is NON\\_COMPLIANT if 'KmsKeyId' is not specified for the Amazon SageMaker endpoint configuration\\. \n",
      "\n",
      "**Identifier:** SAGEMAKER\\_ENDPOINT\\_CONFIGURATION\\_KMS\\_KEY\\_CONFIGURED\n",
      "\n",
      "**Trigger type:** Periodic\n",
      "\n",
      "**AWS Region:** All supported AWS regions except China \\(Beijing\\), Asia Pacific \\(Jakarta\\), Africa \\(Cape Town\\), Middle East \\(UAE\\), Asia Pacific \\(Hyderabad\\), Asia Pacific \\(Osaka\\), Asia Pacific \\(Melbourne\\), Europe \\(Milan\\), AWS GovCloud \\(US\\-East\\), Europe \\(Spain\\), China \\(Ningxia\\), Europe \\(Zurich\\) Region\n",
      "\n",
      "**Parameters:**\n",
      "\n",
      "kmsKeyArns \\(Optional\\)Type: String  \n",
      "Comma\\-separated list of specific AWS KMS key ARNs allowed for an Amazon SageMaker endpoint configuration\\.\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-notebook-instance-kms-key-configured.md \n",
      "Category: security \n",
      "Score: 0.5652\n",
      "  - Text: # sagemaker\\-notebook\\-instance\\-kms\\-key\\-configured<a name=\"sagemaker-notebook-instance-kms-key-configured\"></a>\n",
      "\n",
      "Check whether an AWS Key Management Service \\(KMS\\) key is configured for an Amazon SageMaker notebook instance\\. The rule is NON\\_COMPLIANT if 'KmsKeyId' is not specified for the Amazon SageMaker notebook instance\\. \n",
      "\n",
      "**Identifier:** SAGEMAKER\\_NOTEBOOK\\_INSTANCE\\_KMS\\_KEY\\_CONFIGURED\n",
      "\n",
      "**Trigger type:** Periodic\n",
      "\n",
      "**AWS Region:** All supported AWS regions except China \\(Beijing\\), Asia Pacific \\(Jakarta\\), Africa \\(Cape Town\\), Middle East \\(UAE\\), Asia Pacific \\(Hyderabad\\), Asia Pacific \\(Osaka\\), Asia Pacific \\(Melbourne\\), Europe \\(Milan\\), AWS GovCloud \\(US\\-East\\), Europe \\(Spain\\), China \\(Ningxia\\), Europe \\(Zurich\\) Region\n",
      "\n",
      "**Parameters:**\n",
      "\n",
      "kmsKeyArns \\(Optional\\)Type: String  \n",
      "Comma\\-separated list of AWS KMS key ARNs allowed for an Amazon SageMaker notebook instance\\.\n",
      "--------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sagemaker_docs_v1/points/search \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are SageMaker Geospatial capabilities?\n",
      "A: SageMaker Geospatial capabilities are a set of features within Amazon SageMaker that allow users to perform geospatial operations. These capabilities operate as a managed service, meaning that SageMaker executes operations on behalf of users using AWS-managed hardware. \n",
      "\n",
      "To utilize these capabilities, users need to grant specific permissions through an IAM role, often referred to as an execution role. This role defines what operations SageMaker is allowed to perform on the user's behalf. \n",
      "\n",
      "It's important to note that SageMaker can only carry out operations that have been explicitly permitted by the user through this execution role. Users have the option to create and use a locally available execution role to manage these permissions effectively.\n",
      "Sources:\n",
      "  - File: sagemaker-geospatial-roles.md \n",
      "Category: security \n",
      "Score: 0.6410\n",
      "  - Text: # SageMaker geospatial capabilities roles<a name=\"sagemaker-geospatial-roles\"></a>\n",
      "\n",
      "As a managed service, Amazon SageMaker geospatial capabilities perform operations on your behalf on the AWS hardware that is managed by SageMaker\\. It can perform only operations that the user permits\\.\n",
      "\n",
      "A user can grant these permissions with an IAM role \\(referred to as an execution role\\)\\. \n",
      "\n",
      "To create and use a locally available execution role, you can use the following procedures\\.\n",
      "--------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AWS\n",
    "for i, q in enumerate(questions):\n",
    "    query_index(index=aws_index, model_provider=\"aws\", query=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llamaindex:Querying index: What is SageMaker?\n",
      "INFO:llamaindex:The current model is: aws\n",
      "INFO:llamaindex:Setting Gemini Model...\n",
      "INFO:llamaindex:Setting Gemini LLM: models/gemini-1.5-flash, Embedding: models/embedding-001\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sagemaker_docs_v1.1/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Querying index: What are all AWS regions where SageMaker is available?\n",
      "INFO:llamaindex:The Model provider is already set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What is SageMaker?\n",
      "A: Amazon SageMaker is a fully managed service that enables developers and data scientists to build, train, and deploy machine learning (ML) models.\n",
      "\n",
      "Sources:\n",
      "  - File: sagemaker-projects-whatis.md \n",
      "Category: concepts \n",
      "Score: 0.8262\n",
      "  - Text: ## Do I Need to Create a Project to Use SageMaker Pipelines?<a name=\"sagemaker-projects-need\"></a>\n",
      "\n",
      "No\\. SageMaker pipelines are standalone entities just like training jobs, processing jobs, and other SageMaker jobs\\. You can create, update, and run pipelines directly within a notebook by using the SageMaker Python SDK without using a SageMaker project\\.\n",
      "\n",
      "Projects provide an additional layer to help you organize your code and adopt operational best practices that you need for a production\\-quality system\\.\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-controls.md \n",
      "Category: concepts \n",
      "Score: 0.8023\n",
      "  - Text: # Amazon SageMaker controls<a name=\"sagemaker-controls\"></a>\n",
      "\n",
      "These controls are related to SageMaker resources\\.\n",
      "--------------------\n",
      "\n",
      "  - File: rust_sagemaker_code_examples.md \n",
      "Category: tutorial \n",
      "Score: 0.8016\n",
      "  - Text: ## Actions<a name=\"w14aac14b9c65c13\"></a>\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-marketplace.md \n",
      "Category: concepts \n",
      "Score: 0.7952\n",
      "  - Text: ## Topics<a name=\"sagemaker-marketplace-topics\"></a>\n",
      "+ [SageMaker Algorithms](#sagemaker-mkt-algorithm)\n",
      "+ [SageMaker Model Packages](#sagemaker-mkt-model-package)\n",
      "+ [Sell Amazon SageMaker Algorithms and Model Packages](sagemaker-marketplace-sell.md)\n",
      "+ [Find and Subscribe to Algorithms and Model Packages on AWS Marketplace](sagemaker-mkt-find-subscribe.md)\n",
      "+ [Use Algorithm and Model Package Resources](sagemaker-mkt-buy.md)\n",
      "--------------------\n",
      "\n",
      "  - File: examples-sagemaker.md \n",
      "Category: tutorial \n",
      "Score: 0.7804\n",
      "  - Text: # Working with Amazon SageMaker<a name=\"examples-sagemaker\"></a>\n",
      "\n",
      " Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning \\(ML\\) models\\. See the following resources for complete code examples with instructions\\.\n",
      "\n",
      " [Link to Github](https://github.com/awsdocs/aws-doc-sdk-examples/tree/master/javav2/example_code/sagemaker) \n",
      "\n",
      " [Link to AWS Code Sample Catalog](http://docs.aws.amazon.com/code-samples/latest/catalog/code-catalog-javav2-example_code-sagemaker.html)\n",
      "--------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sagemaker_docs_v1.1/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Querying index: How to check if an endpoint is KMS encrypted?\n",
      "INFO:llamaindex:The Model provider is already set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are all AWS regions where SageMaker is available?\n",
      "A: This question cannot be answered from the given source.\n",
      "\n",
      "Sources:\n",
      "  - File: sagemaker-marketplace.md \n",
      "Category: concepts \n",
      "Score: 0.8007\n",
      "  - Text: ## Topics<a name=\"sagemaker-marketplace-topics\"></a>\n",
      "+ [SageMaker Algorithms](#sagemaker-mkt-algorithm)\n",
      "+ [SageMaker Model Packages](#sagemaker-mkt-model-package)\n",
      "+ [Sell Amazon SageMaker Algorithms and Model Packages](sagemaker-marketplace-sell.md)\n",
      "+ [Find and Subscribe to Algorithms and Model Packages on AWS Marketplace](sagemaker-mkt-find-subscribe.md)\n",
      "+ [Use Algorithm and Model Package Resources](sagemaker-mkt-buy.md)\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-marketplace.md \n",
      "Category: concepts \n",
      "Score: 0.7882\n",
      "  - Text: ## SageMaker Model Packages<a name=\"sagemaker-mkt-model-package\"></a>\n",
      "\n",
      "Buyers use a model package to build a deployable model in SageMaker\\. They can use the deployable model for real\\-time inference by using SageMaker hosting services\\. Or, they can get inferences for an entire dataset by running batch transform jobs\\. For more information, see [Deploy a Model in Amazon SageMaker](how-it-works-deployment.md)\\. As a seller, you can build your model artifacts by training in SageMaker, or you can use your own model artifacts from a model that you trained outside of SageMaker\\. You can charge buyers for inference\\.\n",
      "\n",
      "**Topics**\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-controls.md \n",
      "Category: concepts \n",
      "Score: 0.7835\n",
      "  - Text: # Amazon SageMaker controls<a name=\"sagemaker-controls\"></a>\n",
      "\n",
      "These controls are related to SageMaker resources\\.\n",
      "--------------------\n",
      "\n",
      "  - File: examples-sagemaker.md \n",
      "Category: tutorial \n",
      "Score: 0.7785\n",
      "  - Text: # Working with Amazon SageMaker<a name=\"examples-sagemaker\"></a>\n",
      "\n",
      " Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning \\(ML\\) models\\. See the following resources for complete code examples with instructions\\.\n",
      "\n",
      " [Link to Github](https://github.com/awsdocs/aws-doc-sdk-examples/tree/master/javav2/example_code/sagemaker) \n",
      "\n",
      " [Link to AWS Code Sample Catalog](http://docs.aws.amazon.com/code-samples/latest/catalog/code-catalog-javav2-example_code-sagemaker.html)\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-projects-whatis.md \n",
      "Category: concepts \n",
      "Score: 0.7781\n",
      "  - Text: ## Do I Need to Create a Project to Use SageMaker Pipelines?<a name=\"sagemaker-projects-need\"></a>\n",
      "\n",
      "No\\. SageMaker pipelines are standalone entities just like training jobs, processing jobs, and other SageMaker jobs\\. You can create, update, and run pipelines directly within a notebook by using the SageMaker Python SDK without using a SageMaker project\\.\n",
      "\n",
      "Projects provide an additional layer to help you organize your code and adopt operational best practices that you need for a production\\-quality system\\.\n",
      "--------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sagemaker_docs_v1.1/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:llamaindex:Querying index: What are SageMaker Geospatial capabilities?\n",
      "INFO:llamaindex:The Model provider is already set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: How to check if an endpoint is KMS encrypted?\n",
      "A: This question cannot be answered from the given source.  The provided text describes how to configure KMS keys for various AWS SageMaker resources using CloudFormation templates, but it does not explain how to check if an endpoint is already encrypted with a KMS key.\n",
      "\n",
      "Sources:\n",
      "  - File: sagemaker-endpoint-configuration-kms-key-configured.md \n",
      "Category: security \n",
      "Score: 0.7552\n",
      "  - Text: ## AWS CloudFormation template<a name=\"w2aac12c33c15b9d525c15\"></a>\n",
      "\n",
      "To create AWS Config managed rules with AWS CloudFormation templates, see [Creating AWS Config Managed Rules With AWS CloudFormation Templates](aws-config-managed-rules-cloudformation-templates.md)\\.\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-notebook-instance-kms-key-configured.md \n",
      "Category: security \n",
      "Score: 0.7448\n",
      "  - Text: ## AWS CloudFormation template<a name=\"w2aac12c33c15b9d529c15\"></a>\n",
      "\n",
      "To create AWS Config managed rules with AWS CloudFormation templates, see [Creating AWS Config Managed Rules With AWS CloudFormation Templates](aws-config-managed-rules-cloudformation-templates.md)\\.\n",
      "--------------------\n",
      "\n",
      "  - File: aws-properties-sagemaker-featuregroup-onlinestoresecurityconfig.md \n",
      "Category: properties \n",
      "Score: 0.7441\n",
      "  - Text: ### JSON<a name=\"aws-properties-sagemaker-featuregroup-onlinestoresecurityconfig-syntax.json\"></a>\n",
      "\n",
      "```\n",
      "{\n",
      "  \"[KmsKeyId](#cfn-sagemaker-featuregroup-onlinestoresecurityconfig-kmskeyid)\" : String\n",
      "}\n",
      "```\n",
      "--------------------\n",
      "\n",
      "  - File: aws-properties-sagemaker-featuregroup-onlinestoresecurityconfig.md \n",
      "Category: properties \n",
      "Score: 0.7412\n",
      "  - Text: ### YAML<a name=\"aws-properties-sagemaker-featuregroup-onlinestoresecurityconfig-syntax.yaml\"></a>\n",
      "\n",
      "```\n",
      "  [KmsKeyId](#cfn-sagemaker-featuregroup-onlinestoresecurityconfig-kmskeyid): String\n",
      "```\n",
      "--------------------\n",
      "\n",
      "  - File: aws-properties-sagemaker-modelcard-securityconfig.md \n",
      "Category: properties \n",
      "Score: 0.7348\n",
      "  - Text: ### JSON<a name=\"aws-properties-sagemaker-modelcard-securityconfig-syntax.json\"></a>\n",
      "\n",
      "```\n",
      "{\n",
      "  \"[KmsKeyId](#cfn-sagemaker-modelcard-securityconfig-kmskeyid)\" : String\n",
      "}\n",
      "```\n",
      "--------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sagemaker_docs_v1.1/points/search \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are SageMaker Geospatial capabilities?\n",
      "A: SageMaker geospatial capabilities are a managed service that operates on AWS hardware managed by SageMaker.  They only perform operations explicitly permitted by the user, which are granted through an IAM execution role.\n",
      "\n",
      "Sources:\n",
      "  - File: sagemaker-geospatial-roles.md \n",
      "Category: security \n",
      "Score: 0.7848\n",
      "  - Text: # SageMaker geospatial capabilities roles<a name=\"sagemaker-geospatial-roles\"></a>\n",
      "\n",
      "As a managed service, Amazon SageMaker geospatial capabilities perform operations on your behalf on the AWS hardware that is managed by SageMaker\\. It can perform only operations that the user permits\\.\n",
      "\n",
      "A user can grant these permissions with an IAM role \\(referred to as an execution role\\)\\. \n",
      "\n",
      "To create and use a locally available execution role, you can use the following procedures\\.\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-projects-whatis.md \n",
      "Category: concepts \n",
      "Score: 0.7590\n",
      "  - Text: ## Do I Need to Create a Project to Use SageMaker Pipelines?<a name=\"sagemaker-projects-need\"></a>\n",
      "\n",
      "No\\. SageMaker pipelines are standalone entities just like training jobs, processing jobs, and other SageMaker jobs\\. You can create, update, and run pipelines directly within a notebook by using the SageMaker Python SDK without using a SageMaker project\\.\n",
      "\n",
      "Projects provide an additional layer to help you organize your code and adopt operational best practices that you need for a production\\-quality system\\.\n",
      "--------------------\n",
      "\n",
      "  - File: sagemaker-controls.md \n",
      "Category: concepts \n",
      "Score: 0.7579\n",
      "  - Text: # Amazon SageMaker controls<a name=\"sagemaker-controls\"></a>\n",
      "\n",
      "These controls are related to SageMaker resources\\.\n",
      "--------------------\n",
      "\n",
      "  - File: aws-properties-sagemaker-userprofile-jupyterserverappsettings.md \n",
      "Category: properties \n",
      "Score: 0.7388\n",
      "  - Text: # AWS::SageMaker::UserProfile JupyterServerAppSettings<a name=\"aws-properties-sagemaker-userprofile-jupyterserverappsettings\"></a>\n",
      "\n",
      "The JupyterServer app settings\\.\n",
      "--------------------\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GEMINI\n",
    "for i, q in enumerate(questions):\n",
    "    query_index(index=gemini_index, model_provider=\"gemini\", query=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws-doc-ragqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
